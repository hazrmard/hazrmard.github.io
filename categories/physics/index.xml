<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Physics on Ibrahim Ahmed</title>
    <link>http://iahmed.me/categories/physics/index.xml</link>
    <description>Recent content in Physics on Ibrahim Ahmed</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Ibrahim Ahmed</copyright>
    <atom:link href="http://iahmed.me/categories/physics/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Is cold the new hot?</title>
      <link>http://iahmed.me/post/is_cold_the_new_hot/</link>
      <pubDate>Tue, 31 Jan 2017 11:00:25 -0600</pubDate>
      
      <guid>http://iahmed.me/post/is_cold_the_new_hot/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note: This article was originally published on
&lt;a href=&#34;astroibrahim.wordpress.com&#34;&gt;astroibrahim&lt;/a&gt; on April 17, 2013.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Yes.&lt;/p&gt;

&lt;p&gt;A few days back, a friend shared an
&lt;a href=&#34;http://www.nature.com/news/quantum-gas-goes-below-absolute-zero-1.12146&#34;&gt;article&lt;/a&gt; with me. It talked of
how scientists had managed to achieve temperatures below absolute
zero. Does it mean that temperature has to be redefined? Has our
understanding of thermodynamics been flawed for the past hundred
years. No, it turns out. It is all a matter of semantics.&lt;/p&gt;

&lt;p&gt;Absolute Zero. This is the temperature at which a particle has
the minimum possible energy. The energy is NOT zero because that
would violate the Heisenberg uncertainty principle (that you
cannot know the energy and its duration with absolute certainty).
However that zero-state energy is a quantum quantity, so for all
intents and purposes, the particle itself appears stationary.
Classically, it is impossible to go below absolute zero because
for all the matter that we know of, it will never have negative
energy (because the zero state energy prevents energy from going
past zero and into the negative).&lt;/p&gt;

&lt;p&gt;Therefore when you talk of temperatures below absolute zero, and
you know that there is nothing wrong with absolute zero, then
logically there must be something going on with “Temperature”.
The layperson will call temperature the hotness of something.
Some one more well versed in science will call it the average
kinetic energy of the particles. All of these definitions are
correct in the same way Newton’s gravity is correct i.e. it works
for our observations. But in order to really understand
temperature, you need to understand entropy.&lt;/p&gt;

&lt;p&gt;Entropy in a sense is the amount of disorder in a system. Imagine
making a mound of sand on a table. Now shake the table. The sand
particles will spread out as they roll down from the mound.
Because the particles are now spread out, the entropy of the
system has increased. The farther a particle is from the original
position of the mound, the more effectively it has harnessed the
energy you gave the system by vibrating the table. If the table
was infinitely expansive, the particles would continue spreading
out and absorbing the energy you provide and increasing the
entropy of the system.&lt;/p&gt;

&lt;p&gt;In a system with infinite states, energy and disorder have a
positive relationship.
In a system with infinite states, energy and disorder have a
positive relationship.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;http://iahmed.me/img/posts/temp_infinite.png&#34;&gt;
    &lt;figcaption&gt;In a system with infinite states, energy and
    disorder have a positive relationship.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This is temperature, the ratio of energy required to the change
in entropy. The greater the energy required for the same increase
in entropy, the greater will be the temperature.&lt;/p&gt;

&lt;p&gt;But there is a catch: what if you provide more energy to the
system but the disorder (entropy) decreases instead. Is it
possible to shake the table and make the sand particles more
ordered? If it is, then that would mean that the temperature of
the system is negative because the change in energy is positive,
but the change in entropy is negative, so the ratio (which
represents temperature) is negative. Imagine that the table is
not infinite. Instead it has little walls on the edges. As you
shake the table, the sand particles start to spread out (they
gain energy, and increase entropy). The temperature increases.
But there comes a point when they reach the edges. Then they
start to accumulate again. The more you shake the table, the
greater is the particle accumulation on the edges. At that point,
an increase in energy of the system is in fact decreasing its
disorder. Thus the temperature has become negative.&lt;/p&gt;

&lt;p&gt;In a system with finite states, energy and disorder develop a
negative relationship.
In a system with finite states, energy and disorder develop a
negative relationship.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;http://iahmed.me/img/posts/temp_finite.png&#34;&gt;
    &lt;figcaption&gt;In a system with finite states, energy and  
    disorder develop a negative relationship.&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;That is exactly what the scientists mentioned in the article did.
They trapped the molecules using lasers and magnetic fields, so
that after absorbing certain amount of energy, the barriers
created by the magnetic fields and lasers would cause particles
to accumulate around the same energies. In the classical sense,
the particles were hotter because they had a greater energy, but
since the disorder in the system was lessened, their temperature
was negative i.e. below absolute zero.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gravitational Slingshots</title>
      <link>http://iahmed.me/post/GravitationalSlingshots/</link>
      <pubDate>Tue, 31 Jan 2017 10:48:32 -0600</pubDate>
      
      <guid>http://iahmed.me/post/GravitationalSlingshots/</guid>
      <description>&lt;p&gt;&lt;em&gt;Note: This article was originally published on
&lt;a href=&#34;astroibrahim.wordpress.com&#34;&gt;astroibrahim&lt;/a&gt; on Apr 10, 2013.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I always wondered why doesn’t the sun slow space probes down when
they are leaving the Earth for outer planets. Isn’t there a risk
that the probe might change its trajectory and fall into the sun?
There is. You see, the more distant the space probe gets from the
Sun, the more potential energy it gains. However, energy must be
conserved at all costs. Therefore the probe loses its Kinetic
energy (and therefore its speed) in order to get away from the
sun. It is the same as when you throw a rock up into the air.&lt;/p&gt;

&lt;p&gt;But there comes a point, as with the rock, when the probe loses
all of its kinetic energy. At that time it has reached as far
away from the sun as it can. Yes, you could add thrusters to make
sure the probe continues its journey. But the extra weight and
inefficiency of propellants known to us make it an unsuitable
alternative.&lt;/p&gt;

&lt;p&gt;Enter the Gravitational Slingshot! Nature’s way of compensating
us (very marginally) for all the millions of years we’ve been
dragged through the mud in the name of evolution. Through this
method, space probes go into a partial orbit around a planet and
emerge on the other side with a greater velocity. “No!”, some
might say, because it is a violation of conservation of energy.
Intuitively it seems that way, but it is all a matter of
relativity.&lt;/p&gt;

&lt;figure&gt;
    &lt;img src=&#34;http://iahmed.me/img/posts/slingshot.png&#34;&gt;
&lt;/figure&gt;

&lt;p&gt;Imagine there is a probe approaching a planet with a velocity
‘u’. To an observer on the planet, the apparent velocity of the
probe’s approach will be ‘V+u’, where ‘V’ is the planet’s and ‘u’
is the probe’s heliocentric velocity, i.e. velocity relative to
the Sun. It will go into orbit at that speed. Now, when it comes
out of orbit on the other side, it is still moving with a
velocity ‘V+u’ relative to the planet’s surface. But the planet
is also moving in the same direction at velocity ‘V’. So the
final velocity as the probe leaves orbit will be ‘V+(V+u)’. Of
course, some of that velocity will be reduced due to the planet’s
potential, but in the end it will still be greater than the
probe’s initial velocity.&lt;/p&gt;

&lt;p&gt;If you look at what happened overall, ignoring how it happened,
the probe approaches a moving planet at a certain velocity and
“bounces off” at a higher velocity. It is just like when you
throw a ball at the face of a moving train, the ball bounces off
at a higher velocity. Now, the ball changes its momentum (first
going in one direction, then another) and transfers that change
to the train to ensure conservation. But the train is
comparatively so massive that we do not notice the minuscule
change in its velocity. That’s the same with planets and probes.&lt;/p&gt;

&lt;p&gt;The effective increment in the probe’s velocity is due to the
orbited body’s velocity relative to the Sun (analogously, the
change in velocity of the rebounding ball depends on the train’s
relative velocity to the ground). Of course, the Sun’s velocity
relative to itself is zero. Therefore ‘V’ will be zero. So there
will be no gravitational slingshot from the Sun (towards planets
in its orbit) even though it is the most massive body in the
solar system; just like there will be no increment in the
velocity of the ball when you throw it at the ground.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A case study in choosing algorithms</title>
      <link>http://iahmed.me/post/2016-08-13-a-case-study-in-choosing-algorithms/</link>
      <pubDate>Sun, 14 Aug 2016 03:29:23 +0000</pubDate>
      
      <guid>http://iahmed.me/post/2016-08-13-a-case-study-in-choosing-algorithms/</guid>
      <description>&lt;p&gt;This past year, I have been crunching data from &lt;a href=&#34;https://github.com/hazrmard/DarkMatterHalos&#34;&gt;dark matter simulations&lt;/a&gt;. Data size can get pretty large when it comes to scientific computing. As I write this post, I have a script running on 3.8 TB (that&amp;#8217;s right &amp;#8211; 3,700 gigabytes) of cosmic particles. At these levels one starts thinking about parallelizing computations. And therein lay my dilemma and a soon to be learned lesson.&lt;/p&gt;

&lt;p&gt;Around the time I began working on this, I was taking an algorithms course. And we had just learned about the &lt;a href=&#34;https://en.wikipedia.org/wiki/Bin_packing_problem&#34;&gt;bin packing problem&lt;/a&gt;. It involves figuring out the best way to fit an arbitrary number of objects with different sizes into a set of bins so the least amount of bins are used. And it is a hard problem to figure out fast. To get around the difficulty, computer scientists come up with &lt;a href=&#34;https://en.wikipedia.org/wiki/Heuristic_(computer_science)&#34;&gt;heuristics&lt;/a&gt;: shortcuts that give a &amp;#8220;good enough&amp;#8221; answer. And one heuristic is the First-fit algorithm. Essentially: find the fist bin with enough space, dump the object in, repeat.&lt;/p&gt;

&lt;p&gt;Now, this bin packing problem was similar to my parallelization challenge. I had to divide my data into multiple processes to be computed independently. And so, with the enthusiasm that comes only with applying newfound knowledge, I &lt;a href=&#34;https://github.com/hazrmard/DarkMatterHalos#multi-core-processing&#34;&gt;wrote some code&lt;/a&gt;. It read the data, assigned them &amp;#8220;size&amp;#8221; based on the big-O complexity of my calculations, and binned them for each process. Sweet, right?&lt;/p&gt;

&lt;p&gt;Not so fast. I was noticing that my processes were still taking different times to finish. The disparity was more than I was happy with. There could be several reasons. One, big-O complexity rarely ever translates to proportionate running times as it ignores factors such as OS background. Two, I was not accounting for file i/o and lower-order big-O complexities while &amp;#8220;sizing&amp;#8221; data. In practice vs. theory, these things matter. So what could I do?&lt;/p&gt;

&lt;p&gt;My solution in the end was quite simple, and my biggest lesson with parallel computing. Instead of pre-partitioning data for each process, I kept it all in a single pool. As soon as a process was free, it took one package from the pool and did its thing. The processes naturally divvied up the work. All was well! Now this might be parallel 101 for many, but I was so caught up in the fancy new algorithm I had learned that I did not pause to see if a plebeian approach, so to speak, may work better.&lt;/p&gt;

&lt;p&gt;Now, as my pizza arrives and my script chugs through terabytes of data, I can watch Netflix in peace knowing that my pet processes are making the best of their time.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>